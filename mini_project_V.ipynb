{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Duplicate Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over 100 million people visit Quora every month, so it's no surprise that many people ask similar (or the same) questions. Various questions with the same intent can cause people to spend extra time searching for the best answer to their question, and results in members answering multiple versions of the same question. Quora uses random forest to identify duplicated questions to provide a better experience to active seekers and writers, and offer more value to both of these groups in the long term.\n",
    "Follow the steps outlined below to build the appropriate classifier model. \n",
    "\n",
    "\n",
    "Steps:\n",
    "- Download data\n",
    "- Exploration\n",
    "- Cleaning\n",
    "- Feature Engineering\n",
    "- Modeling\n",
    "\n",
    "By the end of this project you should have **a presentation that describes the model you built** and its **performance**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 404290 entries, 0 to 404289\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   id            404290 non-null  int64 \n",
      " 1   qid1          404290 non-null  int64 \n",
      " 2   qid2          404290 non-null  int64 \n",
      " 3   question1     404289 non-null  object\n",
      " 4   question2     404288 non-null  object\n",
      " 5   is_duplicate  404290 non-null  int64 \n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 18.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note\n",
    "There is no designated test.csv file. The train.csv file is the entire dataset. Part of the data in the train.csv file should be set aside to act as the final testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 404290 pairs of questions\n",
      "There are 149263 pairs of duplicate questions\n",
      "There are 255027 pairs of non-duplicate questions\n",
      "That means that about 36.92 % of the questions are duplicate\n"
     ]
    }
   ],
   "source": [
    "print(\"There are\", len(df), 'pairs of questions')\n",
    "print(\"There are\", len(df[df[\"is_duplicate\"]==1]), 'pairs of duplicate questions')\n",
    "print(\"There are\", len(df[df[\"is_duplicate\"]==0]), 'pairs of non-duplicate questions')\n",
    "\n",
    "\n",
    "print(\"That means that about\",  round(len(df[df[\"is_duplicate\"]==1])/len(df)*100,2), \"% of the questions are duplicate\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning\n",
    "\n",
    "- Tokenization\n",
    "- Stopwords cleaning\n",
    "- Removing punctuation\n",
    "- Normalizing\n",
    "- Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows with nulls and unnecessary columns\n",
    "df = df.dropna()\n",
    "df = df.drop([\"id\", \"qid1\", \"qid2\"],axis=1)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove puncation\n",
    "import string\n",
    "df['question1'] = df['question1'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
    "df['question2'] = df['question2'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokeniation\n",
    "df['question1'] = df['question1'].apply(lambda x: x. split())\n",
    "df['question2'] = df['question2'].apply(lambda x: x. split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removeing stop words\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "ENGstopwords = stopwords.words('english')\n",
    "\n",
    "df['question1'] = df['question1'].apply(lambda x: [word for word in x if word not in ENGstopwords])\n",
    "df['question2'] = df['question2'].apply(lambda x: [word for word in x if word not in ENGstopwords])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"cleaned_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "- tf-idf\n",
    "- word2vec\n",
    "- word count\n",
    "- number of the same words in both questions\n",
    "- ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[What, step, step, guide, invest, share, marke...</td>\n",
       "      <td>[What, step, step, guide, invest, share, market]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[What, story, Kohinoor, KohiNoor, Diamond]</td>\n",
       "      <td>[What, would, happen, Indian, government, stol...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[How, I, increase, speed, internet, connection...</td>\n",
       "      <td>[How, Internet, speed, increased, hacking, DNS]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Why, I, mentally, lonely, How, I, solve]</td>\n",
       "      <td>[Find, remainder, math2324math, divided, 2423]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Which, one, dissolve, water, quikly, sugar, s...</td>\n",
       "      <td>[Which, fish, would, survive, salt, water]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404282</th>\n",
       "      <td>[How, many, keywords, Racket, programming, lan...</td>\n",
       "      <td>[How, many, keywords, PERL, Programming, Langu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404283</th>\n",
       "      <td>[Do, believe, life, death]</td>\n",
       "      <td>[Is, true, life, death]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404284</th>\n",
       "      <td>[What, one, coin]</td>\n",
       "      <td>[Whats, coin]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404285</th>\n",
       "      <td>[What, approx, annual, cost, living, studying,...</td>\n",
       "      <td>[I, little, hairfall, problem, I, want, use, h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404286</th>\n",
       "      <td>[What, like, sex, cousin]</td>\n",
       "      <td>[What, like, sex, cousin]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404287 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question1  \\\n",
       "0       [What, step, step, guide, invest, share, marke...   \n",
       "1              [What, story, Kohinoor, KohiNoor, Diamond]   \n",
       "2       [How, I, increase, speed, internet, connection...   \n",
       "3               [Why, I, mentally, lonely, How, I, solve]   \n",
       "4       [Which, one, dissolve, water, quikly, sugar, s...   \n",
       "...                                                   ...   \n",
       "404282  [How, many, keywords, Racket, programming, lan...   \n",
       "404283                         [Do, believe, life, death]   \n",
       "404284                                  [What, one, coin]   \n",
       "404285  [What, approx, annual, cost, living, studying,...   \n",
       "404286                          [What, like, sex, cousin]   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "0        [What, step, step, guide, invest, share, market]             0  \n",
       "1       [What, would, happen, Indian, government, stol...             0  \n",
       "2         [How, Internet, speed, increased, hacking, DNS]             0  \n",
       "3          [Find, remainder, math2324math, divided, 2423]             0  \n",
       "4              [Which, fish, would, survive, salt, water]             0  \n",
       "...                                                   ...           ...  \n",
       "404282  [How, many, keywords, PERL, Programming, Langu...             0  \n",
       "404283                            [Is, true, life, death]             1  \n",
       "404284                                      [Whats, coin]             0  \n",
       "404285  [I, little, hairfall, problem, I, want, use, h...             0  \n",
       "404286                          [What, like, sex, cousin]             0  \n",
       "\n",
       "[404287 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "df2 =df\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\"\\ndropCount = 0\\n\\nfor i in range(len(df2.index)):\\n    try:\\n        df2[\\'q1_vector\\'][i] = TfidfVectorizer().fit_transform(df2[\\'question1\\'][i])\\n        df2[\\'q2_vector\\'][i] = TfidfVectorizer().fit_transform(df2[\\'question2\\'][i])\\n    except ValueError:\\n        df2 = df2.drop([i])\\n        print(\"dropped\", i)\\n        dropCount = dropCount + 1\\n\\n        \\ndf2 = df2.reset_index(drop=True)\\nprint(\"total drop:\", dropCount)\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df2['q1_vector'] = \"\"\n",
    "df2['q2_vector'] = \"\"\n",
    "\"\"\"\"\"\n",
    "dropCount = 0\n",
    "\n",
    "for i in range(len(df2.index)):\n",
    "    try:\n",
    "        df2['q1_vector'][i] = TfidfVectorizer().fit_transform(df2['question1'][i])\n",
    "        df2['q2_vector'][i] = TfidfVectorizer().fit_transform(df2['question2'][i])\n",
    "    except ValueError:\n",
    "        df2 = df2.drop([i])\n",
    "        print(\"dropped\", i)\n",
    "        dropCount = dropCount + 1\n",
    "\n",
    "        \n",
    "df2 = df2.reset_index(drop=True)\n",
    "print(\"total drop:\", dropCount)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#character count\n",
    "df2['q1_character_count'] = df2['question1'].str.len().astype(float)\n",
    "df2['q2_character_count'] = df2['question2'].str.len()\n",
    "\n",
    "#word count\n",
    "df2['q1_word_count'] = df2['question1'].apply(len)\n",
    "df2['q2_word_count'] = df2['question2'].apply(len)\n",
    "\n",
    "\n",
    "df2['shared_word_count'] = df2.apply(lambda x: len(set(x['question1']) & set(x['question2'])), axis=1)\n",
    "\n",
    "\n",
    "df2['shared_word_percent'] = df2.apply(lambda x: x['shared_word_count'] / (x['q1_word_count'] + x['q2_word_count']) * 100, axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test = df2['is_duplicate']\n",
    "df2 = df2.drop(['is_duplicate'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         <class 'float'>\n",
      "1         <class 'float'>\n",
      "2         <class 'float'>\n",
      "3         <class 'float'>\n",
      "4         <class 'float'>\n",
      "               ...       \n",
      "404282    <class 'float'>\n",
      "404283    <class 'float'>\n",
      "404284    <class 'float'>\n",
      "404285    <class 'float'>\n",
      "404286    <class 'float'>\n",
      "Name: q1_character_count, Length: 404287, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df2['q1_character_count'].apply(type))\n",
    "\n",
    "df2 = df2.drop(['question1','question2','q1_vector','q2_vector'],axis=1)\n",
    "\n",
    "df2 = df2.reset_index(drop=True)\n",
    "df2.to_csv(\"test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "\n",
    "Different modeling techniques can be used:\n",
    "\n",
    "- logistic regression\n",
    "- XGBoost\n",
    "- LSTMs\n",
    "- etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X training shape: (323429, 6)\n",
      "X test shape: (80858, 6)\n",
      "y training shape: (323429,)\n",
      "y test shape: (80858,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df2\n",
    "y = df['is_duplicate']\n",
    "X.reindex\n",
    "\n",
    "# Prepare train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "print(\"X training shape:\", X_train.shape)\n",
    "print(\"X test shape:\", X_test.shape)\n",
    "print(\"y training shape:\", y_train.shape)\n",
    "print(\"y test shape:\", y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Accuracy: 65.5%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.fit_transform(X_test)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_pca, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_pca)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "percent = round(acc, 4) * 100\n",
    "print(f'Test Set Accuracy: {percent}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "df3f64ca5e16a52414df56f6fd8e5b33b60cd9e67139926ade6a9b44fe3fa7c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
